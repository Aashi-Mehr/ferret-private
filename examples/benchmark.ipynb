{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9d24491a",
   "metadata": {},
   "source": [
    "# Introduction to *ferret*\n",
    "\n",
    "Hi there! This notebook will guide you through the basic functionalities of *ferret*, using as an example the Sentiment Classification task.\n",
    "\n",
    "Specifically, you will see how to:\n",
    "\n",
    "- load a model from the Hugging Face Hub into our `Benchmark` client interface;\n",
    "- use the class to explain a text query using all the supported post-hoc feature attribution methods;\n",
    "- visualize the explanations in tabular format;\n",
    "- **evaluate** all the explanations over the metrics (faithfulness and plausibility).\n",
    "\n",
    "Scroll over to know more ðŸ˜‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52852519-03d4-4f7e-8a73-8c80786d5646",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14d18989-fda4-4f8d-b265-2992d9062e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from ferret import Benchmark\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bac7579e",
   "metadata": {},
   "source": [
    "For the purpose of this tutorial, we will use the sentiment classification model `cardiffnlp/twitter-xlm-roberta-base-sentiment`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d537c947-682e-49fd-92d2-bd823bb90808",
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"cardiffnlp/twitter-xlm-roberta-base-sentiment\"\n",
    "model = AutoModelForSequenceClassification.from_pretrained(name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "593830f1",
   "metadata": {},
   "source": [
    "## Explain a single instance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7370ffd4",
   "metadata": {},
   "source": [
    "The fastest way to get started with *ferret* is using the `Benchmark` interface class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "737c9329",
   "metadata": {},
   "outputs": [],
   "source": [
    "bench = Benchmark(model, tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c75cc6b5",
   "metadata": {},
   "source": [
    "Extracting post-hoc explanations with all the supported methods and standard parameters is as easy as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94c4f140",
   "metadata": {},
   "outputs": [],
   "source": [
    "explanations = bench.explain(\"I love your style!\", target=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a1ba65b",
   "metadata": {},
   "outputs": [],
   "source": [
    "explanations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac9f79e2",
   "metadata": {},
   "source": [
    "Let's visualize the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18800ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = bench.show_table(explanations)\n",
    "t"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79dca2c8",
   "metadata": {},
   "source": [
    "## Evaluate explanation of a single instance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e15cf29",
   "metadata": {},
   "source": [
    "Evaluate explanations with all the supported evaluators is straightforward. Remember to specify the `target` parameter to match the one used during the explanation!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ffe8f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "explanation_evaluations = bench.evaluate_explanations(explanations, target=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa0fa638",
   "metadata": {},
   "source": [
    "Again, we can look at the results in a tabular format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa3d689f",
   "metadata": {},
   "outputs": [],
   "source": [
    "bench.show_evaluation_table(explanation_evaluations)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d86def7",
   "metadata": {},
   "source": [
    "Area Over the Perturbation Curve (AOPC) Comprehensiveness (aopc_compr), AOPC Sufficiency (aopc_suff) and Correlation with Leave-One-Out scores (taucorr_loo) are three measures of faithfulness.\n",
    "\n",
    "**AOPC Comprehensiveness**. Comprehensiveness measures the drop in the model probability if the relevant tokens of the explanations are removed. We measure comprehensiveness via the Area Over the Perturbation Curve by progressively considering the most $k$ important tokens, with $k$ from 1 to #tokens (as default) and then averaging the result. The higher the value, the more the explainer is able to select the relevant tokens for the prediction.\n",
    "\n",
    "**AOPC Sufficiency**. Sufficiency captures if the tokens in the explanation are sufficient for the model to make the prediction. As for comprehensiveness, we use the AOPC score.\n",
    "\n",
    "**Correlation with Leave-One-Out scores**. We first compute the leave-one-out scores by computing the prediction difference when one feature at the time is omitted. We then measure the Spearman correlation with the explanations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fff44d00",
   "metadata": {},
   "source": [
    "### Plausibility"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cad0272",
   "metadata": {},
   "source": [
    "We can also specify a human rationale and evaluate plausibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0561e8d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "explanation_evaluations = bench.evaluate_explanations(\n",
    "    explanations,\n",
    "    target=0,\n",
    "    human_rationale=[0, 1, 0, 0, 0],\n",
    "    top_k_rationale=1\n",
    ")\n",
    "bench.show_evaluation_table(explanation_evaluations)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca7a5ac0",
   "metadata": {},
   "source": [
    "Plausibility evaluates how well the explanation agree with human rationale. We evaluate plausibility via \n",
    "Area Under the Precision Recall curve (AUPRC) (auprc_plau),  token-level f1-score (token_f1_plau) and average Intersection-Over-Union (IOU) at the token level (token_iou_plau).\n",
    "\n",
    "\n",
    "**Area Under the Precision Recall curve (AUPRC)** is computed by sweeping a threshold over token scores.\n",
    "\n",
    "Token-level f1-score and the average Intersection-Over-Unionconsider discrete rationales.\n",
    "We derive a discrete rationale by taking the top-k values. K in the example is set to 1. * \n",
    "\n",
    "**Token-level f1-score** is the token-level F1 scores derived from the token-level precision and recall. \n",
    "**Intersection-Over-Union (IOU)** is the size of the overlap of the tokens they cover divided by the size of their union.\n",
    "\n",
    "*When the set of human rationales for the dataset is available, K is set as the average rationale length (as in ERASER)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cabbcb0",
   "metadata": {},
   "source": [
    "# Evaluating explainers on a supported XAI Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e70b2fd",
   "metadata": {},
   "source": [
    "We can directly load a dataset with rationales using our Dataset API -- since we use Hugging Face's [datasets](https://huggingface.co/datasets), you will download the dataset just once and cache it ðŸš€"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23bb7ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "hatexdata = bench.load_dataset(\"hatexplain\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e472f7f8",
   "metadata": {},
   "source": [
    "Here we show an example of text and its human rationales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d082e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "hatexdata[2][\"text\"], hatexdata[2][\"rationale\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83951d6f",
   "metadata": {},
   "source": [
    "We can compute evaluate explanations for a set of the samples of the dataset.\n",
    "\n",
    "As a default, explanations and their evaluation is computed w.r.t. the predicted class. We can otherwise specify the target class via the parameter 'target'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c35ef613",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute and average evaluation scores one of the supported dataset\n",
    "samples = np.arange(1)\n",
    "sample_evaluations =  bench.evaluate_samples(hatexdata, samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e04cc43",
   "metadata": {},
   "source": [
    "and visualize the evaluation results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37506275",
   "metadata": {},
   "outputs": [],
   "source": [
    "bench.show_samples_evaluation_table(sample_evaluations)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0706f67e",
   "metadata": {},
   "source": [
    "# Bonus!\n",
    "\n",
    "There is more! You can:\n",
    "\n",
    "- use *ferret* built-in explainers to have fine-grained control over their *init* and *call* parameters (please refer to our [doc](https://ferret.readthedocs.io/en/latest/?version=latest) to know more)\n",
    "- compute individual faithfulness and plausibility metrics over explanations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "561f2113",
   "metadata": {},
   "source": [
    "**Interface to individual explainers**\n",
    "\n",
    "You can also use individual explainers using an object oriented interface."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77e3877f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ferret import SHAPExplainer, LIMEExplainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52c85a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp = LIMEExplainer(model, tokenizer)\n",
    "exp(\"hello my friend\", target=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e75aa80e-773a-48de-a27f-5eb6cdb670a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp = SHAPExplainer(model, tokenizer)\n",
    "exp(\"hello my friend\", target=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09532fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp = SHAPExplainer(model, tokenizer)\n",
    "e = exp(\"I love your style!\", target = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db355c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "bench.show_table([e])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a55837e",
   "metadata": {},
   "source": [
    "and evaluate an individual evaluation measure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6112eb61",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ferret import AOPC_Comprehensiveness_Evaluation\n",
    "# from ferret.evaluators import ModelHelper\n",
    "\n",
    "aopc_compr_eval = AOPC_Comprehensiveness_Evaluation(\n",
    "    model,\n",
    "    tokenizer,\n",
    "    'text-classification'  # Example task name: it's needed in the constructor.\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdc834d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "aopc_compr_eval.compute_evaluation(e, target = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44661fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ev = bench.evaluate_explanation(e, target = 0)\n",
    "bench.show_evaluation_table([ev])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "d8f902cf6ca391daaec6c50bfce6a52cbc75b613a5db9822f88b522b8035bbf2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
